
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119541534-1');
</script>
		
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Patterson Consulting: Blog - Real-Time Analysis of Computer Vision Objects with TensorFlow and Apache Kafka</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="blog page for Patterson Consulting" />
	<meta name="keywords" content="blog, patterson consulting, deep learning, machine learning, apache hadoop, apache spark, etl, consulting" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}

	</style>

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
					<ul>
						<li><a href="../about.html">About</a></li>
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Services</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../offerings/data_science_offerings.html">Data Science Offerings</a></li>
										<li><a href="../big_data_apps.html">Hadoop Applications</a></li>
										<li><a href="../vision_apps.html">Computer Vision Applications</a></li>
										<li><a href="../sensor_apps.html">Sensor Applications</a></li>
										<li><a href="../exec_strategy.html">Executive Strategy</a></li>

									</ul>
								</div>
							</div>
						</li>
						<!--
						<li><a href="portfolio.html">Portfolio</a></li>
-->
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Technologies</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../deep_learning.html">Deep Learning</a></li>
										<li><a href="../hadoop.html">Apache Hadoop</a></li>										
									</ul>
								</div>
							</div>
						</li>
						
						<li><a href="../blog/blog_index.html">Blog</a></li>
					
						<li class="cta"><a href="../contact.html">Contact</a></li>
					</ul>
				</nav>
			</div>
		</header>
		<!-- Header -->


		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h1>Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision (Part 2)</h1>
						<p>Author: <a href="http://www.twitter.com/jpatanooga">Josh Patterson</a> and Stuart Eudaly</p>
						<p>Date: Sept 16th, 2019</p>
						
						<p>
							<i>In this blog article we take on the perspective of the enterprise development team of a fictional Fortune 500 Retailer "Big Cloud Dealz" looking to integrate emerging technology to re-invent the in-store customer experience. We wanted to tell the story of how the <a href="../offerings/data_science_offerings.html">Patteson Consulting team would help</a> a fictional enterprise navigate the evolution towards digital transformation.</i>

						</p>


					</div>
				</div>
				<!-- end of section -->


				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Prototyping Shopping Cart 2.0 with Computer Vision</h2>

						<p>
							In our last article we .... [ TODO ]

						</p>



						<p>


						<div style="float: right; margin: 12px; border: 1px solid #999999;">
						<iframe width="560" height="315" src="https://www.youtube.com/embed/Xkwl0k_p3FI" style=" margin: 6px;" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
						<p style="margin-left: 12px; width: 560px;">Demonstration of <a href="../../vision_apps.html"><i>object detection</i></a>. Object detection<sup>objdet</sup> in computer vision is defined as finding objects in images with “0 to multiple objects per image”. Each object prediction is accompanied by a bounding box and a class probability distribution.</p>
						</div>		







						</p>
						<p>					

							The team has stated they need to do some <a href="https://www.oreilly.com/ideas/solving-real-world-business-problems-with-computer-vision">computer vision</a> on the contents of the cart, but they don't have the resources to get too exotic. The development team has read a lot about <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">object detection</a> lately in the domain of <a href="https://ai.googleblog.com/2018/07/accelerated-training-and-inference-with.html">computer vision</a> and they know there are a lot of pre-trained models available for TensorFlow. After watching several demos and videos of applied object detection models, they decide on leveraging one of the models provided in the TensorFlow object deteciton project.

						</p>
						<p>


						We need to know what's happening real-time in those shopping carts, but can't spend a ton of time developing the cart sensor because management wants to see a working prototype "soon". The data science team ran some tests on available pre-trained models and observed that our shopping cart bottoms have an odd pattern that tends to disrupt certain item's classifications with the model.

					</p>

					<p>



						The SVP of Application Development doesnt want to spend on a custom model (yet). They arent sure of the value of collecting a lot of custom shopping cart image data, and they want to see what <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">stock models</a> can do first. If we can get a basic model working to show "something", we likely will get the green light to iterative improve Shopping Cart 2.0 with more custom models based on our earlier models.



					</p>
					<p>
						<b>The team understands that if they can get a basic model working and it drives upsell opportunities (and revenue), then they will have the opportunity to iteratively improve model accuracy which will further drive revenue.</b> The focus for now is to just get the basic cart camera application working.


					</p>

						
		

					


					</div>
				</div>
				<!-- end of section -->

				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Selecting an Initial Object Detection Model</h2>


						<div style="float: right; margin: 12px; border: 1px solid #999999;">
						<img src="./images/bcd_shopping_cart_frisbees.jpg" style="width: 430px; height: 461px; float: right; margin: 12px; border: 1px solid #999999;" />
						<p style="margin-left: 12px; width: 430px;">R-CNN pre-trained model output rendered on input image of a ball and two frisbees with bounding boxes and classifications.</p>
						</div>		

					<p> Given that we need an android device on the cart itself to collect images of the basket items, it makes sense that we <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md">run the model "at the edge"</a><sup>model-edge</sup> on the cart android device, and only send the model predictions. Model predictions are produced through a process known as "inference" where we take input data and let it do a forward pass through the network. The output layer gives us the prediction, and that's the output we'll send on to the rest of the application. Another advantage of doing inference on the Android devices is that it allows us to leverage all of the CPUs in our fleet of Shopping Cart 2.0's as opposed to having a bank of GPUs back in the data warehouse. 



					</p>
					<p>To summarize the process:

						<ol>
							<li>Periodically take a picture of the contents of the basket</li>
							<li>Use the picture as input to the local model and get the output of the inference as the object detections</li>
							<li>Pass each detected object (name of items, bounding box coordinates) to the Kafka system via the <a href="https://docs.confluent.io/current/clients/producer.html">Producer API</a> for aggregation in real-time</li>

						</ol>


					</p>

				<div style="float: left; margin: 12px; border: 0px solid #999999;">
					<iframe src="http://www.oreilly.com/authors/widgets/782.html" height="380px" width="200px" scrolling="no" frameborder="0"></iframe>							
				</div>	

					
					<p>
						Given that our mandate is to use off-the-shelf components as much as possible to rapidly prototype, we're going to work with a pre-trained model from the <a href="https://www.tensorflow.org/">TensorFlow</a> <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">model zoo</a>. TensorFlow has a lot of community traction and support so the team wants to try and leverage one of object detection models offered from their website. The team has found some ARM9 boards (that will run <a href="https://www.tensorflow.org/mobile/android_build">TensorFlow on Android</a> with WIFI connectivity) with cameras for under $150, so creating 100 Shopping cart 2.0 prototypes loaded up with an object deteciton model should cost around $15k for hardware. Another advantage is that TensorFlow has JVM bindings that run on Android as well, which can be integrated with the JVM code from Kafka.

					</p>




					<p>
						The team scans the TensorFlow model zoo and <a href="https://makarandtapaswi.wordpress.com/2012/07/02/intuition-behind-average-precision-and-map/">reads up on mAP scores</a> as an overall indication of model quality (Resources on <a href="https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3">Understanding object detection and mAP scores</a>, and <a href="https://arxiv.org/abs/1611.10012">understanding speed/accuracy trade-offs in object detection</a>). Inference speed is general a concern, but given that this was a prototype and the team was more interested in a better mAP value, it was less of a concern here. The application did not need to produce a lot of inferences, so a few seconds of latency between taking the picture and sending object detections back to the Kafka cluster was not a big deal.


					</p>

					<p>

						The team chooses the <a href="http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz">COCO-pretrained Faster R-CNN with Resnet-101 model</a> because of its general mAP accuracy and decent file size. The team gave a lot of consideration to the YOLOv2 model variant, but ended up going for another model that was slower but gave a better mAP score for the application (which makes a lot of difference when we're using a stock model for prototyping). The data scientist is relieved to know that there are resources for easily <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md">training a future custom model</a> on specific basket images (Example: <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md">Training a pet detector based on Faster R-CNN Resnet 101</a>) once they get the prototype system running for management.

					</p>
					<p>
						With the base system design in place, the team could then move on to getting JVM code working that would take a custom image as input and produce a raw inference output that could be passed to the <a href="https://docs.confluent.io/current/clients/producer.html">Kafka Producer API</a>, as we see being done in the next section.

					</p>




					</div>
				</div>
				<!-- end of section -->


				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Object Detection Model Inference at the Edge with TensorFlow</h2>

						<p>
							In this section we'll focus on getting TF setup with java code, the model loaded, and inferences produced from the model to send to the kafka cluster.


							The core java classes for this object detection system running on each cart are listed below:
							<ul>
								<li><a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java">TFVision_ObjectDetection.java</a>: code to run the model inference with TensorFlow</li>
								<li><a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java">TFModelUtils.java</a>: support utilities for TensorFlow</li>
								<li><a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/VisualObject.java">VisualObject.java</a>: class to represent detected objects from model inference output</li>
								<li><a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java">ObjectDetectionProducer.java</a>: code tying the TensorFlow code into the <a href="https://docs.confluent.io/current/clients/producer.html">Kafka producer API</a>, more on that a bit later</li>

							</ul>
							To get this project going we'll use Apache Maven so we'll need a pom.xml to bring in the needed dependencies. Below we see a portion of the <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/pom.xml">pom.xml</a> file with the dependencies of note:
						</p>


							<script src="http://gist-it.appspot.com/https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/pom.xml?slice=59:102"></script>

							<p>

							We can see the confluent dependencies that will support the <a href="https://docs.confluent.io/current/clients/producer.html">Kafka Producer API</a> operations along with the TensorFlow dependencies needed to load a pre-trained model (component versions are in the variables section of the pom.xml file; specifically we're using TensorFlow 1.8 in this example). 

						</p>
						<p>
							Let's take a closer look at how we'll load the TensorFlow model and make inferences in java with the TensorFlow R-CNN object detection model. In the code section below, we can see the <code><a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L96">scanImageForObjects(...)</a></code> method highlighted which performs the bulk of the work in the class.


						</p>



							<script src="http://gist-it.appspot.com/https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java?slice=95:140"></script>

						

						<p>
							The <code><a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L96">scanImageForObjects(...)</a></code> method takes 3 parameters:

							<ol>
								<li><b>modelFile</b>: the TensorFlow object detection model to load for inference</li>
								<li><b>labelMapFile</b>: list of labels the associated <b>modelFile</b> can output (e.g., "the vocabulary of labels the saved model understands")</li>
								<li><b>inputImageFile</b>: the image file path that we want to use as input to the <b>modelFile</b> to get object detections as output from</li>

							</ol>

							This class is a convinient wrapper around the base TensorFlow classes needed to load a <code><a href="https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/SavedModelBundle">SavedModelBundle</a></code> and produce inference output on an arbitrary TensorFlow model.							
							We'll point out a few key areas in the TensorFlow code above:<br/><br/>

							<ul>
								
								
								<li>Working with <code><a href="https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/SavedModelBundle">SavedModelBundle</a></code>, frozen graphs, and .pb files</li>
								<li><a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java">TFModelUtils.java</a></li>

								
								<li>Converting TensorFlow output into <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/VisualObject.java">VisualObject</a> class instances</li>

							</ul>

							The <code>SavedModelBundle</code> is handy because it all of the needed files to run a TensorFlow object detection model.

							The <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java">TFModelUtils.java</a> class is of note because it wraps functionality for doing things like <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java#L69">loading label files</a> and <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java#L95">converting the image file input</a> into the proper vectorized <Code>Tensor&lt;UInt8&gt;</code> format. 

							After we get the output of the scores, classes, and bounding boxes from the TensorFlow inference output, the code <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L160">converts these into a our VisualObject</a> class wrappers to make them more easy to with.
							Now that we've located the <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/VisualObject.java">VisualObjects</a> in our basket and given them classifications, let's move on to how we'll send the classified objects to the Kafka cluster for processing.

						</p>

					</div>
				</div>
				<!-- end of section -->



				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Integrating Shopping Cart 2.0 Detected Objects into an Apache Kafka Producer</h2>
						<p>
							To write data to a Kafka topic we need to use the Kafka Producer API. Apache Kafka is a JVM-based system so that makes it a relatively simple process to tie the object detection code into the code using the Producer API. In this example, we can see this happening in the <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java">ObjectDetectionProducer.java</a> class.

							We can see the code for this class highlighted below.

							

						</p>
						
							
							<script src="http://gist-it.appspot.com/https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java?slice=112:172"></script>							

						
						<p>
							We'll highlight a few key areas of the code:

							<ol>
								<li>Specifying a <A href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L167">Kafka topic</a> to send messages to</li>
								<li>Configuring the producer to <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L124">use the Avro GenericRecord API</a></li>
								<li>Laying out an <A href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L81">Avro schema</a> for the GenericRecord API to use</li>
								<li>Configuring the producer <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L116">properties</a></li>
								<li>Scanning all <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L173">image files in a directory</a></li>
								<li>Watching a <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L224">directory for incoming files</a></li>
								<li>Main <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L113">run loop</a> of the producer</li>
								
							</ol>

							The producer class can either scan a pre-existing directory and index all of the objects in the images of the directory or watch a directory for images as they arrive. The producer class uses the <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java">TFVision_ObjectDetection.java</a> we outlined in the previous section to analyze the images in the directory. The TFVision_ObjectDetection.java class's <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L96"><code>scanImageForObjects(...)</code></a> method produces object detections which are then sent to the configured Kafka topic <code>shopping_cart_objects</code>. If we update our general architecture diagram from above it now looks like:


						</p>

						<div style="float: left; margin: 12px; border: 0px solid #999999;">

							<img src="./images/bcd_arch_part_2.png" style="width: 587px; height: 418px;" />

						</div>

						<p>
							We've configured this example to use the GenericRecord Avro API and the code contains an embedded Avro schema so that we can leverage the GenericRecord API as we're prototyping this application at this stage (for more details on how to use the Generic and SpecificRecord Avro API, check out our <A href="http://www.pattersonconsultingtn.com/blog/avro_101_w_kafka.html">blog post on Using Apache Avro with Apache Kafka</a>). We also include the address of the <a href="https://www.confluent.io/blog/schema-registry-kafka-stream-processing-yes-virginia-you-really-need-one/">Confluent Schema Registry</a> so the schema can be archived in its central Avro schema repository. 

						</p>



						<p>
							For demo purposes, this producer will come alive and then scan the image files in the directory we specify on the command line when we run the <a href="https://github.com/pattersonconsulting/kafka_tf_object_detection/blob/master/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L201">ObjectDetectionProducer.java</a> class. We include a set of pictures of items in shopping baskets for this demo, and we'll point the <code>ObjectDetectionProducer</code> class at the directory that contains this photos to run this demo.

					</div>
					<div class="col-md-12" id="fh5co-content">
						At this point the BCD has some working object detection code for cart 2.0 that will send detected objects to <Code>shopping_cart_objects</code> topic in a Kafka cluster. However, we don't have our Kafka system setup nor configured, so we're going to wait until part 3 of this series to run this code (because we have no where to send the detections right now).
					</div>

				</div>
				<!-- end of section -->

				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Running the Prototype Cart Camera Application</h2>

						<p>

							[ here ]



						</p>
						
						


					</div>
				</div>
				<!-- end of section -->

				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Summary</h2>

						<p>
							In part 2 of this series on re-inventing the shopping cart we walked the reader through:

							<ol>
								<li>Selecting an object detection model</li>
								<li>Integrating the model to serve predictions</li>
								<li>Wiring the predictings into Kafka with the Producer API</li>


							</ol>

							In part of our 3-part series, we'll show how we take the real-time incoming shopping cart data and aggregate it to drive a new level of shopping experience in the store.


						</p>
						
						


					</div>
				</div>
				<!-- end of section -->


						<div style="border: 1px solid #999999; background-color: #EEEEEE; padding: 16px; margin: 32px;">

						<h3>More Notes on Model Integration and Model Lifecycle Management</h3>
						  <p>
						  <i>
						  	Obviously for this example we're hard-wiring a model into the Shopping Cart 2.0 project in a way that's great for proof of concepts yet doesnt address many of the production lifesycle issues that arise.
						  	Some of these considerations include:

							<ul>
								
								<li>Why not send images to Kafka or the Data Lake?</li>
								<li>How often do we retrain this model?</li>								
								<li>How would we swap out or roll-back the model in production?</li>
								
							</ul>
							One great reason to not send images back to the data lake is that we might capture someone's kids' images which could cause legal issues in certain scenarios. Another reason for not capture the images is from a pure resource standpoint as it would require more store and processing resources to be used to move the images around.


							</i></p>
							<p><i>
								The R-CNN model the team uses in this example is good to prove to management that this concept "works", yet has a limited initial vocabulary of objects it can recognize. A real production version of this model would need to fine-tune against the full inventory of the retail chain and would require retraining everytime the store carried a new item. A re-train event would need to be done in a batch setting back on the Data Lake probably leveraging GPUs.

							</i></p>

							<p><i>
								Once we have a new re-trained model, we'll need to be able to deploy the model to system. We have two options: we either deploy it each night after the store closes, or we do it while people are shopping and using the system. We feel the best approach in terms of model management long-term is to leverage a <A href="https://www.oreilly.com/ideas/integrating-convolutional-neural-networks-into-enterprise-applications">model server system</a> so the support / Ops team can treat each model as it would a RDBMS table. 

<!--
								There are several variants of model servers today, a few notable ones:

								<ul>
									<li>Official <a href="https://github.com/tensorflow/serving">TensorFlow Serving Project</a> and then Google's cloud model hosting offerings</li>
									<li>Hosting <a href="https://docs.microsoft.com/en-us/visualstudio/ai/tensorflow-vm">TensorFlow models on an Azure VM</a>, Deploying <a href="https://docs.microsoft.com/en-us/azure/machine-learning/desktop-workbench/model-management-service-deploy">model as web service</a> on Azure</li>
									<li>Cloudera's <a href="https://www.cloudera.com/documentation/data-science-workbench/latest/topics/cdsw_overview.html">Data Science Workbench</a></li>

									<li>Amazon <A href="https://aws.amazon.com/blogs/machine-learning/introducing-model-server-for-apache-mxnet/">MXNet Model Server</a></li>
									

									<li>Skymind's <a href="https://docs.skymind.ai/docs">SKIL Model Server</a> for TensorFlow model hosting</li>
									<li>The <A href="https://mlflow.org/">MLFlow</a> open source project</li>

								</ul>

							-->

								For the purposes of brevity and practicality in this example, we will not integrate a model server and will leave that as an exercise for the reader to explore later.

							</i></p>


						</div>	




			</div>
		</div>






		<!-- Slider -->
		<!--
		<footer id="fh5co-footer" role="contentinfo">
			<div class="container">
				<div class="row row-bottom-padded-sm">
					<div class="col-md-4 col-sm-12">
					</div>
					<div class="col-md-3 col-md-push-1 col-sm-12 col-sm-push-0">
						<div class="fh5co-footer-widget">
						</div>
					</div>
					<div class="col-md-3 col-md-push-2 col-sm-12 col-sm-push-0">
						
						<div class="fh5co-footer-widget">
							<h3>Follow us</h3>
							<ul class="fh5co-social">
								<li class="twitter"><a href="https://twitter.com/PattersonCnsltg"><i class="icon-twitter"></i></a></li>
								<li class="linkedin"><a href="https://www.linkedin.com/in/joshlpatterson/"><i class="icon-linkedin"></i></a></li>
								<li class="message"><a href="mailto:josh@pattersonconsultingtn.com"><i class="icon-mail"></i></a></li>
							</ul>
						</div>
					</div>

				</div>

			</div>
		</footer>
	-->
	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>
