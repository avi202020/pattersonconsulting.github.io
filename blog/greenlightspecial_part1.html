
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119541534-1');
</script>
		
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Patterson Consulting: Blog - Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision - Part 1 of 4</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="blog page for Patterson Consulting" />
	<meta name="keywords" content="blog, patterson consulting, deep learning, machine learning, apache hadoop, apache spark, etl, consulting" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content="Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision - Part 1 of 4"/>

	<meta property="og:image" content="http://www.pattersonconsultingtn.com/blog/images/big_cloud_dealz_logo2.png"/>
	<meta property="og:url" content="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part1.html"/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content="Building a real time shopping cart analysis system for real world retailers with computer vision and apache kafka."/>
	

	<meta name="twitter:title" content="Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision - Part 1 of 4" />
	<meta data-rh="true" property="twitter:description" content="Building a real time shopping cart analysis system for real world retailers with computer vision and apache kafka."/>

	<meta name="twitter:image" content="http://www.pattersonconsultingtn.com/blog/images/big_cloud_dealz_logo2.png" />
	<meta name="twitter:url" content="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part1.html" />
	<meta name="twitter:card" content="summary_large_image" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}

	</style>

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
					<ul>
						<li><a href="../about.html">About</a></li>
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Services</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../offerings/data_science_offerings.html">Data Science Offerings</a></li>
										<li><a href="../big_data_apps.html">Hadoop Applications</a></li>
										<li><a href="../vision_apps.html">Computer Vision Applications</a></li>
										<li><a href="../sensor_apps.html">Sensor Applications</a></li>
										<li><a href="../exec_strategy.html">Executive Strategy</a></li>

									</ul>
								</div>
							</div>
						</li>
						<!--
						<li><a href="portfolio.html">Portfolio</a></li>
-->
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Technologies</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../deep_learning.html">Deep Learning</a></li>
										<li><a href="../hadoop.html">Apache Hadoop</a></li>										
									</ul>
								</div>
							</div>
						</li>
						
						<li><a href="../blog/blog_index.html">Blog</a></li>
					
						<li class="cta"><a href="../contact.html">Contact</a></li>
					</ul>
				</nav>
			</div>
		</header>
		<!-- Header -->

<!--
		<div class="fh5co-slider" >
			<div class="container" >
				
				<div class="cd-hero__content cd-hero__content--half-width" style="width: 80%; padding-left: 50px;">
						<h1>Rail, Aquariums, and Data</h1>
				</div>		
			</div>
		</div>
-->

		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h1>Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision</h1>
						<h3>Part 1 of 4</h3>
						<p>Authors: <a href="http://www.twitter.com/jpatanooga">Josh Patterson</a>, Stuart Eudaly, Austin Harris</p>
						<p>Date: October 23, 2019</p>
						
						<p>
							<i>In this series of blog articles, we take on the perspective of the enterprise development team of a fictional Fortune 500 Retailer "Big Cloud Dealz" looking to integrate emerging technology to re-invent the in-store customer experience.</i>

						</p>


						<img src="./images/big_cloud_dealz_logo2.png" style="width: 300px; height: 315px; float: left; margin: 12px; border: 0px solid #999999;" />

						<p>


							Retail stores are under more pressure than ever to "be like Amazon.com" in terms of tailoring the shopping experience for customers. This is especially true with Amazon's acquisition of Whole Foods and their original concept "AmazonGo." On the online front, we see shoppers expecting a customized shopping experience with recommendations based on their past viewing habits. We also see Amazon innovating with a storefront that mimics the online experience with a dizzying array of <a href="https://www.washingtonpost.com/news/business/wp/2018/01/22/inside-amazon-go-the-camera-filled-convenience-store-that-watches-you-back">sensors and cameras</a>. This series of blog posts gives a real world example in how a non-Amazon retailer could add some of these features to their retail experience by leveraging Apache Kafka (specifically Confluent's enterprise platform) and advanced object detection in computer vision. The <a href="https://www.forbes.com/sites/retailwire/2016/09/21/can-robo-carts-improve-the-walmart-shopping-experience/#3529caed1b22">shopping experience arms race</a> has begun and there is <a href="https://www.cnbc.com/2018/01/17/coming-to-a-grocery-store-near-you-self-driving-carts-smart-shelves.html">no turning back now</a>.

						</p>

						<p>

							The venerable brick-and-mortar retailer "Big Cloud Dealz" badly wants to compete with the evolving shopping landscape and has made the concerted effort to integrate emerging technologies into their customer experience. Founding CEO, "Big Cloud Ron" (<A HREF="https://twitter.com/BigCloudRon1">@BigCloudRon</a>), loves technology but has been burned in the past by fancy tech ideas. Big Cloud Ron has mandated that IT approach this project in a way that is iterative and adaptable as they figure out "what works" and "what does not."
						</p>
						<p>

							So, with the stage being set, we take a look at the notes from the first meeting where the enterprise team kicks off their project:

						<div style="float: right; margin: 12px; border: 1px solid #999999;">
						<iframe width="560" height="315" src="https://www.youtube.com/embed/3UjhFM7OejM" style=" margin: 6px;" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
						<p style="margin-left: 12px;">A Commerical for the K-Mart Blue Light Special</p>
						</div>
<!--
							<iframe width="560" height="315" src="https://www.youtube.com/embed/3UjhFM7OejM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
-->
							<ul>
								
								<li>Big Cloud Ron wants to increase engagement with his customers in a unique, personalized, and timely way that drives upsell. He wants to combine real people with technology -- something online retail cannot do.</li>

								<li>He wants customers to interact with a salesperson "at the right time in the right context." Big Cloud Ron, being a student of retail history, wants a modern version of the classic <A href="https://en.wikipedia.org/wiki/Kmart">K-Mart Blue Light Special.</a><sup>1</sup></li>

								<li>He wants the team to create the following effect in store with technology: create a dynamic in-store special that will prompt a sales associate to move to a specific aisle to upsell a specific product based on some business logic based on what people are shopping for "at that moment."</li>
								<li>He wants to offer a dynamic special that will have the chance to create the most extra margin possible. So, it will be necessary to know the summary of what items are in everyone's basket combined before they hit the registers.</li>
								
							</ul>



						</p>
						<p>

							Since we now know what management wants, let's take a look at the system architecture necessary to accomplish it.

						</p>


					</div>
				</div>
				<!-- end of section -->

				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Application Architectural Overview</h2>
						<p>

							Now that IT knows the business goal, here are a few key points they need to focus on to implement this system:

							<ul>
								
								
								<li>Latency is a big deal for this application. If they don't have the aggregate contents of all the shopping baskets in a timely fashion, they can't make a business decision on which items to offer the upsell on in real-time. This makes their biggest focus to be on the streaming aspect of this application. The team has been reading a lot about how much success other companies have had with Apache Kafka, so they want to give that a shot.</li>
								<li>Kafka will handle the data ingest and aggregation part, but they still need a way to see the contents of all shoppers' shopping baskets while they shop. The team knows that object detection has gotten a lot better recently, so they want to leverage that to index the baskets' contents. They'll also need some sort of device attached to the shopping cart that can run this detection algorithm and send the output to the Kafka system.</li>
								
								<li>They don't really want to process this data in batch because latency is a killer for this situation. The longer they wait, the more likely the shopper is either in line for checkout or out of the store.</li>
								<li>They're going to leverage Confluent's packaging of Apache Kafka as their streaming data collection and processing system.</li>
								
							</ul>

							
							The team realizes they need to measure activity in the retail store in the same way they track shoppers in a web-based store. Ultimately, what is happening here is that they will instrument and analyze the physical world much in the same way they would treat a webserver or analyze web logs. They want to see not only what happened, but predict what they should do next.
							
						</p>

						<p>
							<h3>Digging into the Apache Kafka Platform</h3>

							<img src="./images/kafka_logo.png" style="width: 250px; height: 85px; float: right; margin: 12px; border: 0px solid #999999;" />


							The Big Cloud Dealz application development team has been to a few conferences and is interested in building on a solid real-time platform. They've heard a lot about Apach Kafka so they are going to base their application design on that platform as they are largely focused on collecting large amounts of streaming data and being able to run business rules against aggregates of this data. The <a href="https://docs.confluent.io/current/streams/index.html">Kafka streaming API</a> seems like a great fit to implement this concept, as Kafka has many examples of applications being able to react to data in-flight before it hits the data lake. A few other aspects of Kafka catch the team's attention:

							<ul>
								<li>The type of application they were looking for wasn't as good of a fit for the batch world due to the latency requirements.</li>
								<li>Streaming apps tended to differ from MapReduce (or Spark, batch, etc.) applications as they tended to implement core function of the business as opposed to computing analytics.</li>
								


						<li>Real-time apps <a href="https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/">work better as event-driven</a>, while database-based applications are fundamentally table driven.</li>

						
								
								<li>Having stream processing mechanics built into the ingest platform is handy and <a href="https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/">more efficient than trying to cobble this together from multiple systems</a>.</li>
								<li>Given that the team had to build an embedded application for Shopping Cart 2.0, being able to build everything else on a single platform was a benefit.</li>

							</ul>

							The application development team checked out Confluent's blog for more ideas and saw where machine learning had been <a href="https://www.confluent.io/blog/build-deploy-scalable-machine-learning-production-apache-kafka/">applied in general</a> along with <a href="https://www.confluent.io/blog/predicting-flight-arrivals-with-the-apache-kafka-streams-api/">predicting flight arrivals</a>.


						

						




						</p>

						<p>



							A quote from Confluent's site goes on to state:


						<blockquote class="w3-panel w3-leftbar w3-light-grey" style="padding: 16px; font-size: 12px;">
						  <p style="font-size: 14px;">
						  <i>"Consider a simple model of a retail store. The core streams in retail are sales of products, orders placed for new products, and shipments of products that arrive. The “inventory on hand” is a table computed off the sale and shipment streams which add and subtract from our stock of products on hand. Two key stream processing operations for a retail outlet are re-ordering products when the stock starts to run low, and adjusting prices as supply and demand change."</i></p>
						  <p>Jay Kreps' Blog Article: <a href="https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/">"Introducing Kafka Streams: Stream Processing Made Simple"</a></p>
						</blockquote>		

						The team also likes the idea of Kafka (as opposed to trying to put something together themselves) because they don't have to maintain another custom, internally-built system. Why? When building complex systems there are only so many parts you want to "own" as many things become a rabbit hole that distract from your end goal and most folks don't have time to miss their project dates.		

						<h3>The General Application Architecture</h3>			

						Based on several whiteboarding sessions, the team comes up with a general design for what they want to do with the "Green-Light Special" application. In the diagram below, we see the architectural overview for this streaming Kafka-based application.
						</p>
						<p>
							<img src="./images/cloud_dealz_arch_design_start.png" style="width: 938px; height: 296px;" />
						</p>








						The team has broken up the applicaiton into 3 major components in the architectural diagram above:

							<ol>
								<li>A shopping cart (2.0) with an attached camera and wifi unit (likely an ARM-based embedded system) with an object detection model loaded to <a href="http://www.iraj.in/journal/journal_file/journal_pdf/12-201-144871022643-46.pdf">detect specific objects</a> from the camera.</li>
								<li>A Kafka cluster back in the data center to collect all of the incoming data from the shopping carts, organizing it into logical topics for processing.</li>
								<li>A group of streaming applications leveraging Kafka's Streaming API to give the retail store's team a real-time look at what items are in customers' baskets across the store.</li>
								

							</ol>

							While the Big Cloud Dealz team is a big fan of Apache Hadoop, notice that the architecture above does not include (at this point) any sort of "data lake" to land the data. Some types of data have value that is a direct function of how long it takes to make the data actionable. In the case of trying to analyze shoppers' baskets in real time, it doesn't make a lot of sense to push this data to HDFS first. They find it far more favorable (for latency purposes) to have the data driving business insights as it comes in, which keeps the data's value high. With the basic architecture laid out, we'll take a look in the upcoming blog posts at specific parts of the application the team needs to develop.

						</p>

						<p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I DONT NEED COMPUTER VISION BECAUSE I CAN SEE THE FUTURE. AND IN THE FUTURE I BRING THE BLUE LIGHT SPECIAL BACK TO RETAIL. AND IT WILL BRING THE WOOOOO BACK TO RETAIL.</p>&mdash; BigCloudRon (@BigCloudRon1) <a href="https://twitter.com/BigCloudRon1/status/1027260844269346817?ref_src=twsrc%5Etfw">August 8, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>							

						</p>



						<p>
							<h3>Summary and Next Steps</h3>

							In this blog post, we saw a new business plan developed by Big Cloud Dealz to update their in-store retail experience. 

							In the <a href="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part2.html">next post in this series</a> we'll look at the object detection portion of that system along with sending those detected objects to Kafka.

<!--
							In the <a href="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part2.html">next post in this series</a> we'll look at the object detection portion of that system along with sending those detected objects to Kafka.
						-->

						</p>
						<br/><br/><br/><br/>


		
						<p>
							<h5>Footnotes</h5>
							<i>1. In popular culture, <a href="https://en.wikipedia.org/wiki/Kmart">Kmart became known for its "Blue Light Specials."</a> These occurred at surprise moments when a store worker would light up a mobile police light and offer a discount in a specific department of the store while announcing the discounted special over the store's public address system.</i>
						</p>
		
					</div>
				</div>

				



			</div>
		</div>






		<!-- Slider -->
		<!--
		<footer id="fh5co-footer" role="contentinfo">
			<div class="container">
				<div class="row row-bottom-padded-sm">
					<div class="col-md-4 col-sm-12">
					</div>
					<div class="col-md-3 col-md-push-1 col-sm-12 col-sm-push-0">
						<div class="fh5co-footer-widget">
						</div>
					</div>
					<div class="col-md-3 col-md-push-2 col-sm-12 col-sm-push-0">
						
						<div class="fh5co-footer-widget">
							<h3>Follow us</h3>
							<ul class="fh5co-social">
								<li class="twitter"><a href="https://twitter.com/PattersonCnsltg"><i class="icon-twitter"></i></a></li>
								<li class="linkedin"><a href="https://www.linkedin.com/in/joshlpatterson/"><i class="icon-linkedin"></i></a></li>
								<li class="message"><a href="mailto:josh@pattersonconsultingtn.com"><i class="icon-mail"></i></a></li>
							</ul>
						</div>
					</div>

				</div>

			</div>
		</footer>
	-->
	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>
