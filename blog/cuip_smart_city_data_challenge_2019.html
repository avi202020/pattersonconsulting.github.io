
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119541534-1');
</script>
		
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Patterson Consulting: The CUIP Smart City Data Challenge</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="blog page for Patterson Consulting" />
	<meta name="keywords" content="blog, patterson consulting, deep learning, machine learning, apache hadoop, apache spark, etl, consulting" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}

	</style>

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
					<ul>
						<li><a href="../about.html">About</a></li>
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Services</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../big_data_apps.html">Hadoop Applications</a></li>
										<li><a href="../vision_apps.html">Computer Vision Applications</a></li>
										<li><a href="../sensor_apps.html">Sensor Applications</a></li>
										<li><a href="../exec_strategy.html">Executive Strategy</a></li>

									</ul>
								</div>
							</div>
						</li>
						<!--
						<li><a href="portfolio.html">Portfolio</a></li>
-->
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Technologies</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../deep_learning.html">Deep Learning</a></li>
										<li><a href="../hadoop.html">Apache Hadoop</a></li>										
									</ul>
								</div>
							</div>
						</li>
						
						<li><a href="../blog/blog_index.html">Blog</a></li>
					
						<li class="cta"><a href="../contact.html">Contact</a></li>
					</ul>
				</nav>
			</div>
		</header>
		<!-- Header -->

<!--
		<div class="fh5co-slider" >
			<div class="container" >
				
				<div class="cd-hero__content cd-hero__content--half-width" style="width: 80%; padding-left: 50px;">
						<h1>Rail, Aquariums, and Data</h1>
				</div>		
			</div>
		</div>
-->

		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h1>Announcing The CUIP 2019 Smart City Data Challenge</h1>
						


						<p>


							This year the <A href="https://www.utccuip.com/">Center for Urban Informatics and Prgoress (CUIP)</a> program is putting on its second annual data science conference (link to 2018 conference). 

							This year the 2019 CUIP conference is focused on analysis of smart city data and is also putting on a data modeling competition that ties into the conference focus with the theme: 
						</p>
						<p style="font-size: 150%;">

							<i><b>"Predicting Urban Air Pollution Levels From Weather Data and Street Video Events"</b></i>
						</p>

						<div style="float: right; margin: 12px; border: 1px solid #999999;">
						<iframe width="560" height="315" src="https://www.youtube.com/embed/Xkwl0k_p3FI" style=" margin: 6px;" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
						<p style="margin-left: 12px;"><i>Video: Example object detection (YOLO v2) video footage<br/> from Broad Street in Chattanooga</i></p>
						</div>


						<p>


							The CUIP program has been steadily building out its smart city platform for data collection at the pole and wide scale data ingest into a data lake. 

							
							<A href="https://www.utc.edu/faculty/mina-sartipi/index.php">Dr. Sartipi</a> and UTC decided to release a portion of the CUIP data collected from the testbed to further engage the research community on the fruits of the data collection. To support the focus of the conference the data release is kicked off with the <A href="https://www.utccuip.com/smart-city-data-challenge-dataset">CUIP 2019 Smart City Data Challenge</a> for anyone and everyone to participate.

						</p>
						<p>

							 Patterson Consulting (as a CUIP supporter) has been involved in advising on the infrastructure architecture along with design of the CUIP Smart City Data Challenge. This support falls in line with Patterson Consulting's <a href="http://www.pattersonconsultingtn.com/blog/dlchatt2018/rail_aquarium_data_intro.html">long term support of regional research output</a> and its correlation with regional economic growth and development.

						</p>

						<h2>What is the Data Challenge?</h2>

						<p>

							The 2019 Smart City Data Challenge is focused on predicting <A href="https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm">PM2.5</a> levels in the air from the recently open sourced CUIP 2019 Challenge Dataset. The CUIP program is interested in multiple domains related to smart city analytics, but this year they are focused specifically on how smart city's can be improved with sensor deployment across the city. One of the first applications of this sensor deployment is understanding how traffic can affect quality of life in a city, specifically traffic's impact on people's health. 

						</p>
						<p>
							The concept of the CUIP Dataset is largely drawn from the purpose and success of the <a href="http://www.image-net.org/">ImageNet dataset</a>. Machine learning research in any domain cannot move forward without good open datasets, no matter how exotic the applied machine learning methods are. To drive smart city application research forward it was concluded that the CUIP program needed to be a leader in building quality smart city datasets. Just like with <a href="http://image-net.org/about-overview">the ImageNet dataset</a>, the CUIP research group built a dataset and then created a competition and <a href="https://www.utccuip.com/2019-dl-conference">conference</a> to get like-minded researchers in the same room to talk about the problem space.
						</p>
						<p>

							For this data challenge we're looking to predict <A href="https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm">PM2.5</a> levels each day based on cars passing through the smart city corridor and local weather from the sensor stations in the corridor. If we can build a model to predict pollution levels at the intersection-level in an urban environment, we can build potentially build a more detailed pollution map of urban areas and better understand how our cities work. This contest is unique in how we're using both weather data and urban street level object detection data combined to predict pm2.5 levels where most competitions so far have used only weather data.

						</p>
						<h3>Similar Competitions</h3>
						<p>

							In recent years there have been similar competitions predicting pm2.5 levels from previous hours/days of weather data. Kaggle ran a competition in 2018 for <a href="https://www.kaggle.com/c/pm25-prediction/data">predicting pm2.5 values based on weather in Chinese cities</a>. Also in <a href="https://biendata.com/competition/kdd_2018/">2018 we saw the ACM SIG KDD competition</a> focused on predicting "the PM2.5, PM10, and O3 concentration levels over the coming 48 hours for every measurement station in Beijing".

							

						</p>
						<p>


							<h3>What is pm2.5?</h3>



							<A href="https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm">PM2.5</a> is short hand for any atmospheric particulate matter (PM) that has a diameter of less than 2.5 micrometers. For reference this matter is about 3% the diameter of a human hair.
						</p>

							<h3>Why is pm2.5 Dangerous in our Cities?</h3>

							<p>

							Studies in large cities have <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4740125/">shown to be associated with respiratory system disease</a> in humans.
						</p>
						<p>

							From Wikipedia:

							

						<blockquote class="w3-panel w3-leftbar w3-light-grey" style="padding: 16px; font-size: 12px;">
						  <p style="font-size: 14px;">
						  <i>“In 2013, a study involving 312,944 people in nine European countries revealed that there was no safe level of particulates and that for every increase of 10 μg/m3 in PM10, the lung cancer rate rose 22%. The smaller PM2.5 were particularly deadly, with a 36% increase in lung cancer per 10 μg/m3 as it can penetrate deeper into the lungs.[11] Worldwide exposure to PM2.5 contributed to 4.1 million deaths from heart disease and stroke, lung cancer, chronic lung disease, and respiratory infections in 2016.”</i></p>
						  <p><a href="https://en.wikipedia.org/wiki/Particulates">"Wikipedia Entry on 'Particulates'"</a></p>
						</blockquote>

						Further:

						<blockquote class="w3-panel w3-leftbar w3-light-grey" style="padding: 16px; font-size: 12px;">
						  <p style="font-size: 14px;">
						  <i>“Traffic congestion increases vehicle emissions and degrades ambient air quality, and recent studies have shown excess morbidity and mortality for drivers, commuters and individuals living near major roadways. Presently, our understanding of the air pollution impacts from congestion on roads is very limited. ”</i></p>
						  <p><a href="https://www.ncbi.nlm.nih.gov/pubmed/23500830">K. Zhang, S. Batterman; “Air pollution and health risks due to vehicle traffic”, Sci. Total Environ., 450–451 (2013), pp. 307-316</a></p>
						</blockquote>

						It stands to reason that better understanding air pollution beyond the granularity of the city-level has value to the citizens and government of any city.
					</p>



							<h3>Where does pm2.5 come from?</h3>
							<p>


							There are some natural sources of pm2.5 levels such as forest fires, agricultural burning, volcanic eruptions and dust storms. Our focus here is how a city can be impacted by human sources of pm2.5. These human-based sources include 

							<ul>
								<li>power plants</li>
								<li><a href="https://www.ncbi.nlm.nih.gov/pubmed/23500830">motor vehicles</a></li>
								<li>airplanes</li>
								<li>residential wood burning</li>
								<li><a href="http://www.airquality.org/LandUseTransportation/Documents/Ch3ConstructionFINAL5-2017.pdf">construction sites</a></li>
							</ul>
							
							So now that we know a little more about pm2.5, let's better understand how the CUIP data challenge is setup.
							

						</p>


						<h2>The CUIP Smart City Data Challenge Dataset</h2>
						
						<img src="./images/cuip_camera_sample_shot.png" style="width: 640px; height: 360px; float: right; margin: 12px; border: 0px solid #999999;" />


						<p>
							The intial idea for the dataset release was to provide researchers an easy way to work with smart city data such that they could experiment and come up with novel applications. Bringing software into the CUIP platform, while possible, is not as simple as "just working with data". From that perspective, we wanted to give the data community some data so they could get something to work with in their own time and potentially reference the data in their own research.
						</p>
						<p>
							The best exemplar we had was how ImageNet (coupled with the rise of GPUs) helped <A href="http://image-net.org/about-publication">drive huge gains in model accuracy for computer vision research</a>. This gave us the idea of creating an "ImageNet for Smart City", and this is how the CUIP Smart City Dataset was born.
						</p>
						<p>
							The base hypothesis was that early analysis showed pm2.5 levels on the street correlated over time with vechicles passing through the street. However, there were other factors in play such as:

							<ul>
								<li>weather</li>
								<li>type of vehicle</li>
								<li>construction around the sensor pole</li>
								<li>time of day</li>
							</ul>

							It's worth noting that the two previously mentioned competitions around predicting pm2.5 levels were focused mostly on using weather data as the independent input variables. In our case the contestants can use weather data as input but they also can use more fine grain data per intersection (e.g., "vehicle detections") based on the data collected by the CUIP data platform. This allows us to model pm2.5 levels at a more granular resolution that better allows us to understand how it affects specific neighborhoods in a city on a per-intersection level.


						</p>

						<p>
							Just like with understanding how cars move through an intersection can make traffic operations more efficient, we can better design and operate cities when we <a href="https://www.ncbi.nlm.nih.gov/pubmed/26773394">understand how pollution affects sections of our city</a>. As car usage has increased in over-subscribed urban areas, we see their emissions significantly rise in relative contribution to city pollution. As cities become more complex with the rise of global population it is critical to measure and understand all aspects of how we operate cities.

						</p>


						<!--
						<p>
							"Due to the large
increase of personal cars in many areas, the
vehicle emissions have become the dominant
source of air pollutants, including carbon
monoxide (CO), carbon dioxide (CO2), volatile
organic compounds (VOCs) or hydrocarbons
(HCs), nitrogen oxides (NOx), and particulate
matter (PM) [1]."

1]. D. Fecht, A.L. Hansell, D. Morley, D.
Dajnak, D. Vienneau, S. Beevers, M.B.
Toledano, F.J. Kelly, H.R. Anderson, J.
Gulliver; “Spatial and temporal associations
of road traffic noise and air pollution in
London: implications for epidemiological
studies”, Environ. Int., 88 (2016), pp. 235-
242.

						</p>
					-->

						<p>

							This competition is based around further exploring how the main independent variable (vehicle object counts from video frame analysis) along with weather data <b style="color: red;">can more accurately predict the pm2.5 levels during the day</b>.

						</p>





						<p>
							This is a compelling use of video frame detected objects becasue it potentially makes it far simpler to build fine-grained pollition maps of cities.

						</p>


						<h3>Going Beyond Just Cleaning Up the City</h3>




						<div style="float: right; margin: 12px; border: 1px solid #999999; width: 560px;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/o0WM0T4oaAg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<!--
						<p style="margin-left: 12px;"><i>Chattanooga was one of the nation's dirtiest at one point</i></p>
	-->					  


						
						</div>


						<p>
							Finally, we'll note how the city has come full circle from being named infamously by Walter Cronkite as "America's Dirtiest City" on the evening news. To be fair, he wasn't wrong as the lead paragraph from the March 4, 1969 Chattanooga Times read:
						</p>

						  <p style="font-size: 14px; padding: 6px;">
						  <i>"Chattanooga's particulate air pollution is ranked the worst in the nation for the period of 1961-65 in an 1,800-page publication on Air Quality Criteria for Particulate Matter just released by the Department of Health, Education and Welfare."</i></p>

						  <p style="font-size: 14px; padding: 6px;"><a href="https://www.timesfreepress.com/news/local/story/2019/mar/03/moments-memory-how-chattanoogcleaned-its-act/489833/">The Times Free Press: "How Chattanooga cleaned up its act after being named the dirtiest city in America", March 4, 1969</a></p>

						  <p style="font-size: 100%;">


						It's an inspiring story to see the city once labeled as the nation's dirtiest transform itself into being a city that is on the forefront of building next-generation smart city pollution maps.
							 

						</p>




						<h3>Dataset Structure</h3>
						<p>
							The <a href="https://www.utccuip.com/smart-city-data-challenge-dataset">CUIP Smart City Dataset</a> is divided into two major parts:

							<ol>
								<li>Daily air quality data</li>
								<li>Object detections from video frames</li>
							</ol>
						</p>
						<p>
							The air quality data is collected from the Purple Air Sensor located at each intersection along the smart corridor. Each reading includes columns such as humidity and temperature. It also has the PM2.5 level for the same point in time along with other particulate types. Take a look at the dataset website to see all of the columns.

						</p>

						<p>
							Releasing the dataset involved a few challenges, namely the limitation that CUIP was not allowed to release image data from any of the cameras on the smart corridor. With that restriction in mind, the CUIP program used open source computer vision models to produce object detections on the data and then save only the detected objects in their data lake internally.
						</p>

						<p>
							The object detection data is in the other main directory in the dataset and contains daily object detections as they occured per intersection.


							The object detection data was more complex to release due to limitations around what information could be released.

							The CUIP program could not release the video data itself, so instead they decided to release the detected objects from the video frames. These object detections were produced with the <A href="https://pjreddie.com/darknet/yolo/">YOLOv2 Convolutional Neural Network computer vision model</a> along with some custom scene object tracking code developed by the CUIP program.


						</p>
						
						<div style="float: right; margin: 12px; border: 1px solid #999999;">
						<img src="./images/cuip_object_counts_example.png" style="width: 566px; height: 321px; margin: 12px; border: 0px solid #999999;" />

						<p style="margin-left: 12px;"><i>Graphed sample of object detection data per hour at each intersection.</i></p>
						</div>


						<p>
							We'll note that the YOLOv2 model has its tradoffs but coupled with the object tracking methods developed by the CUIP program it was able to achieve good accuracy. Given that the YOLOv2 object detections are consistently effective across all frames in all intersections, any missed detections or duplicated detections should normalize out in the input data normalization/standardization/vectorization process. Beyond these disclaimers, we'll also note that this is real-life data and a seasoned practitioner will realize that many times we must deal with data that needs to be cleaned up. 
						</p>
						<p>

							We consider having to deal with complex data to be part of the competition and we look forward to hearing the methods used by the top 3 teams during the conference on the winners panel.

						</p>
<!--
						<h3>Dataset Schema: Key Variables</h3>
						
						<p>



							[ TODO ]


						</p>

						<h3>Other Compelling Datasets of Note

						<p>



							other datasets: NOAA


						</p>

					-->

						<h3>Competition Rules</h3>

						<p>
							This contest is based around “Predicting Urban Pollution Levels From Street Video Events and Weather”.

						</p>
						<p>
							The specific goal of the contest is to use <a href="https://www.utccuip.com/smart-city-data-challenge-dataset">3 weeks of CUIP basic weather information and object detections</a> to build a model to predict the pm2.5 level for each hour (top of hour) in a day (7am-7pm, top of the hour) for every intersection across 5 days.

						</p>
						<h4>Training Data</h4>
						<p>
							The training data will consist of 3 weeks of CUIP collected data containing: 
							<ol>
								<li>weather</li>
								<li>pm2.5</li>
								<li>vehicle object detections</li>
							</ol>

							All data is in the CSV text file format.

						</p>
						<h4>Held Out Prediction Data</h4>
						<p>
							The held out data for the prediction task will contain:
							<ol>
								<li>weather</li>
								<li>vehicle object detections</li>
							</ol>

							All data is in the CSV text file format.


						</p>
						<p>
							The prediction output will be for all 7 intersections 
							from 7am-7pm (12 hours) on the top of hte hour for 5 days. This will be a prediction submission file containing 336 predictions.
						</p>
						<h4>Submitting an Entry</h4>
						<p>
							
							Teams can submit multiple times to the competition. Each submission will consist of a CSV file in the format:
<code><pre>date,time_hour,intersection_index,pm2_5_value
2019-06-01,7:00,1,100.0
2019-06-01,8:00,1,100.0
2019-06-01,9:00,1,100.0
2019-06-01,10:00,1,100.0
2019-06-01,11:00,1,100.0
...
</pre></code>

							An example submission template can be seen here.

							</p>
						<p>


							
							Each team will save their entry in the above CSV file format and email it to [austin?@utc.org]


						</p>
						<h4>Evaluation Method</h4>

						<p>
							The evaluation metric will be <A href="https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regrression-metrics-3606e25beae0">Mean Square Error (MSE)</a> across all predictions.

						</p>
						<p>
							A leaderboard will list the top 5 entries / teams and will be updated twice a week (Tuesdays and Fridays) leading up to the conference.

						</p>
						<p>
							Top 5 teams will have to send in model for confirmation once the competitions has ended.

						</p>

						<h4>Contest Deadlines</h4>

						<p>
							The deadline for model submission: Sept 6th, 2019.

						</p>
						<h4>Contest Winners and Competitors at the 2019 CUIP Conference</h4>

						<p>

							<b>All teams who participate are invited to present a poster for their methods at the 2019 CUIP conference in Chattanooga, TN during the poster session of the conference.</b> 

						</p>
						<p>

							The top 3 teams will be invited to be on the panel during the conference to discuss the dataset and their techniques for getting the best results.

						</p>						

						<h2>Brief Overview of the CUIP Platform Architecture</h2>

						<p>

							The <a href="https://www.utccuip.com/testbed-2">CUIP platform</a> has stations along intersections down M.L.King Blvd in downtown Chattanooga, TN, as shown in the image below.

						</p>

						<img src="./images/cuip_smart_city_corridor_map.png" style="width: 759px; height: 489px; margin: 12px; border: 0px solid #999999;" />


						<p>
							Each intersection sensor groups has:
							<ul>
								<li>cameras</li>
								<li><A href="https://oceanservice.noaa.gov/facts/lidar.html">LIDAR</a></li>
								<li>RADAR</li>
								<li>microphones</li>

							</ul>

							These sensors generate data readings locally and these data readings are collected and ingested with <A href="http://kafka.apache.org/">Apache Kafka</a> into the CUIP internal data lake. From there the team is able to process and analyze the data with tools such as:

							<ul>
								<li>python and pandas</li>
								<li>GPUs and TensorFlow</li>
								<li>Kubernetes and Kubeflow</li>

							</ul>

							With a deployment of sensors at the edge, an enterprise-class data collection/ingestion system (Apache Kafka), and modern data analysis tools, the CUIP team has been able to drive new use cases of smart city data. For more details on the hardware installed on the CUIP smart city platform, check out their <a href="https://www.utccuip.com/features">features page</a>.


						</p>


						<h2>R and Python Code to Get You Started</h2>

						<p>

							Some of the seasoned data scientists out there may jump right in and start downloading data to analyze with their favorite tools and methods. However, for our newer data scientist friends, we wanted to provide some sample data and an <A href="https://github.com/pattersonconsulting/cuip_2019_data_challenge/tree/master/notebooks">example notebook (hosted on Github)</a> on how to work with the data in python with pandas. We hope this allows people who just want to learn more about the CUIP dataset challenge an easier way to work with the data in a friendly Jupyter notebook environment. In the image below we can see some operations being performed on the sample object detection data from the dataset.


						</p>


						<img src="./images/cuip_data_sample_notebook.png" style="width: 1139px; height: 422px; margin: 12px; border: 0px solid #999999;" />

						And then an <a href="https://cerebralmastication.github.io/cuip_2019_data_challenge/">R-based notebook example</a> from <a href="https://twitter.com/CMastication">James Long</a>:


						<div style="float: right; margin: 12px; border: 1px solid #999999;">


						<a href="https://cerebralmastication.github.io/cuip_2019_data_challenge/">
						<img src="./images/r_notebook_james_long.png" style="width: 955px; height: 586px; margin: 12px; border: 0px solid #999999;" />
						</a>

						<p style="margin-left: 12px;"><i></i></p>
						</div>

						<h3>List of Example Notebooks</h3>



						<p>
							List of pre-built notebooks to use the data:

							<ul>

								<li><a href="https://twitter.com/CMastication">James Long</a> (of <a href="https://rc2e.com/">R Cookbook fame</a>) provided an <a href="https://cerebralmastication.github.io/cuip_2019_data_challenge/">R-based notebook</a> for the competition</li>

								<li>Basic data loading <a href="https://github.com/pattersonconsulting/cuip_2019_data_challenge/tree/master/notebooks">python notebook from our github account</a></li>

							</ul>


							

							The notebook is assuming you <a href="https://cscdc-2019.utccuip.com/CSCDC+Dataset+Preview.zip">downloaded the CUIP data sample (4.2MB)</a> and saved it in your local notebook directory.



						</p>

						<p>
							Even if you don't participate in the competition, it might be fun to play around with the data and see what you can learn about how traffic moves through MLK street in Chattanooge. We'd love to hear your stories at the competition at the coffee or poster sessions.

						</p>



						<h2>See You at the 2019 CUIP Smart City Conference</h2>

						<div style="float: right; margin: 12px; border: 1px solid #999999;">


<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3266.5215429026175!2d-85.31132638547197!3d35.0436976722798!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x88605e7c73cb3f0b%3A0x8a9795245d49a8ea!2sThe+Edney+Innovation+Center!5e0!3m2!1sen!2sus!4v1566442133291!5m2!1sen!2sus" width="600" height="450" frameborder="0" style="border:0" allowfullscreen></iframe>	

						<p style="margin-left: 12px;"><i>Map to the Edney Center.</i></p>
						</div>


						<p>

							Good luck to all participants in the <A href="https://www.utccuip.com/smart-city-data-challenge-dataset">2019 CUIP Smart City Data Challenge</a>. Come check out the winning team's methods at the <a href="https://www.utccuip.com/2019-dl-conference">2019 CUIP Deep Learning Conference</a> in Chattanooga, TN at the Edney Center on September 13th, 2019. Be sure to catch talks at the conference by companies such as:

							<ul>
								<li>The Google Cloud Team</li>
								<li>Nvidia</li>
								<li>Ford</li>

							</ul>

							and more.


							Looking forward to seeing everyone there.

						


						</p>


				<div style="float: left; margin: 12px; border: 0px solid #999999;">
					<iframe src="http://www.oreilly.com/authors/widgets/782.html" height="380px" width="200px" scrolling="no" frameborder="0"></iframe>							
				</div>	


					</div>
				</div>
				<!-- end of section -->






			</div>
		</div>




	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>
