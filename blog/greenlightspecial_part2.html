
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119541534-1');
</script>
		
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Patterson Consulting: Blog - Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision - Part 2 of 4</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="blog page for Patterson Consulting" />
	<meta name="keywords" content="blog, patterson consulting, deep learning, machine learning, apache hadoop, apache spark, etl, consulting" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content="Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision - Part 2 of 4"/>

	<meta property="og:image" content="http://www.pattersonconsultingtn.com/blog/images/big_cloud_dealz_logo2.png"/>
	<meta property="og:url" content="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part2.html"/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content="Building a real time shopping cart analysis system for real world retailers with computer vision and apache kafka."/>
	

	<meta name="twitter:title" content="Building the Next-Generation Retail Experience with Apache Kafka and Computer Vision - Part 2 of 4" />
	<meta data-rh="true" property="twitter:description" content="Building a real time shopping cart analysis system for real world retailers with computer vision and apache kafka."/>

	<meta name="twitter:image" content="http://www.pattersonconsultingtn.com/blog/images/big_cloud_dealz_logo2.png" />
	<meta name="twitter:url" content="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part2.html" />
	<meta name="twitter:card" content="summary_large_image" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}

	</style>

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
					<ul>
						<li><a href="../about.html">About</a></li>
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Services</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../offerings/data_science_offerings.html">Data Science Offerings</a></li>
										<li><a href="../big_data_apps.html">Hadoop Applications</a></li>
										<li><a href="../vision_apps.html">Computer Vision Applications</a></li>
										<li><a href="../sensor_apps.html">Sensor Applications</a></li>
										<li><a href="../exec_strategy.html">Executive Strategy</a></li>

									</ul>
								</div>
							</div>
						</li>
						<!--
						<li><a href="portfolio.html">Portfolio</a></li>
-->
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Technologies</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../deep_learning.html">Deep Learning</a></li>
										<li><a href="../hadoop.html">Apache Hadoop</a></li>										
									</ul>
								</div>
							</div>
						</li>
						
						<li><a href="../blog/blog_index.html">Blog</a></li>
					
						<li class="cta"><a href="../contact.html">Contact</a></li>
					</ul>
				</nav>
			</div>
		</header>
		<!-- Header -->


		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h1>Building the Next-Gen Retail Experience with Apache Kafka and Computer Vision</h1>
						<h3>Part 2 of 4</h3>
						<p>Authors: <a href="http://www.twitter.com/jpatanooga">Josh Patterson</a>, Stuart Eudaly, Austin Harris</p>
						<p>Date: October 23, 2019</p>
						<p>
							<i><a href="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part1.html">In our last blog post</a>, we saw a new business plan developed by Big Cloud Dealz to update their in-store retail experience. In this post, we'll look at the object detection portion of that plan, along with sending those detected objects to Kafka.</i>
						</p>
						<h2>Prototyping Shopping Cart 2.0 with Computer Vision</h2>



						<p>


						<div style="float: right; margin: 12px; border: 1px solid #999999;">
						<iframe width="560" height="315" src="https://www.youtube.com/embed/Xkwl0k_p3FI" style=" margin: 6px;" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
						<p style="margin-left: 12px; width: 560px;">Demonstration of <a href="../../vision_apps.html"><i>object detection</i></a>. Object detection in computer vision is defined as finding objects in images with “0 to multiple objects per image.” Each object prediction is accompanied by a bounding box and a class probability distribution.</p>
						</div>		







						</p>
						<p>					

							The team has stated they need to do some <a href="https://www.oreilly.com/ideas/solving-real-world-business-problems-with-computer-vision">computer vision</a> on the contents of the cart, but they don't have the resources to get too exotic. They've read a lot about <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">object detection</a> lately in the domain of <a href="https://ai.googleblog.com/2018/07/accelerated-training-and-inference-with.html">computer vision</a> and they know there are a lot of pre-trained models available for TensorFlow. After watching several demos and videos of applied object detection models, they decide on leveraging one of the models provided in the TensorFlow object detection project.

						</p>
						<p>


						They need to know what's happening in real-time in those shopping carts, but can't spend a ton of time developing the cart sensor because management wants to see a working prototype "soon." The data science team ran some tests on available pre-trained models and observed that the shopping cart bottoms have an odd pattern that tends to disrupt certain item's classifications with the model.

					</p>

					<p>



						The SVP of Application Development doesn't want to spend on a custom model (yet). They aren't sure of the value of collecting a lot of custom shopping cart image data, and they want to see what <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">stock models</a> can do first. If they can get a basic model working to show "something," they will likely get the green light to iteratively improve Shopping Cart 2.0 with more custom models based on the earlier models.



					</p>

						
		

					


					</div>
				</div>
				<!-- end of section -->

				<!-- Start SIDEBAR on Transfer Learning -->
				<div style="border: 1px solid #999999; background-color: #EEEEEE; padding: 16px; margin: 32px;">

					<h3>Refining Models for Specific Use Cases with Transfer Learning</h3>
					<p>
						<i>
						  	Stock models can work well out of the gate as we'll see through the progression of this blog article. However, many use cases require a certain level of accuracy on a task to be relevant from a business standpoint (e.g., "we have to be able to detect N% of objects in a shopping basket before the upsell makes us money"). The background of the shopping basket and the specific inventory shapes tend to mess with the object detection system somtimes and would need to be accounted for in the model.
						  	</i>
						  </p>
						  <o>
						  	<i>

						  	We could raise the accuracy of the stock computer vision model by collecting more images of the specific inventory items sitting inside specific types of shopping carts and then building a set of labels (e.g., "bounding boxes + classifications") for the new specific dataset. We'd then take this new data and the "base" stock model from the TensorFlow model zoo and further train the existing model. This technique in known as "transfer learning" in the field of computer vision and deep learning.


						</i>

					</p>
					<p>
						<i>

							Transfer learning has a few variants, but the classic case is where we take an existing convolutional neural network from a model repository such as the TensorFlow model zoo and further train it with domain-specific data. More specifically:

						<blockquote class="w3-panel w3-leftbar w3-light-grey" style="padding: 16px; font-size: 12px;">
						  <p style="font-size: 14px;"><i>

						  "In this variant of transfer learning, we see a CNN model trained on a large data‐ set such as ImageNet, and then we replace the last “classifier layer” with some‐ thing specific to the fine-tuning dataset. Some variants will continue to perform backpropagation on all of the layers, and others will update only the later layers. This is because many of the earlier-layer features are general to all types of vision processing and there is less need to update them. The later layers are focused on combining these lower-level features in task-specific ways and are more relevant to train on the domain-specific dataset."</i></p>

						  <p>Oreilly's <a href="http://www.oreilly.com/authors/widgets/782.html">"Deep Learning: A Practitioner's Approach"</a>, Patterson / Gibson 2017</p>
						</blockquote>	

					</i>

					</p>
					<p>
						<i>
							Another great reason to use transfer learning is because models quickly "age" as the distribution of the image data shifts. This means, as the inventory in the store (for example) gets updated, the model will be less effective at detecting specific objects in the basket as some inventory items will be knew and then some inventory items will get dropped. We need a way to keep our model "fresh" and will likely have to periodically rebuild the model (or <a href="http://www.pattersonconsultingtn.com/offerings/data_science_offerings.html">have someone do it for us with a managed model service</a>). Managing model versions also becomes an issue as we begin to rotate new versions of models into / out of production. This topic is addressed in the sidebar at the end of this article.

						</i>

					</p>

					<p>
						<i>
							For the purposes of building this sample application we aren't going to fine tune the shopping cart computer vision model. In a future article beyond this 4 part series, the Patterson Consulting team will show examples of transfer learning in action for a specific domain. An existing example of transfer learning in action is the <A href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md">TensorFlow pet detector example</a>.

						</i>

					</p>


				</div>
				<!-- End SIDEBAR on Transfer Learning -->


				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Selecting an Initial Object Detection Model</h2>


						<div style="float: right; margin: 12px; border: 1px solid #999999;">
						<img src="./images/bcd_shopping_cart_frisbees.jpg" style="width: 430px; height: 461px; float: right; margin: 12px; border: 1px solid #999999;" />
						<p style="margin-left: 12px; width: 430px;">R-CNN pre-trained model output rendered on input image of a ball and two frisbees with bounding boxes and classifications.</p>
						</div>		

					<p> Given that they need an Android device on the cart itself to collect images of the basket items, it makes sense that they <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md">run the model "at the edge"</a> on the cart Android device, and only send the model predictions. Model predictions are produced through a process known as "inference" where input data is taken and does a forward pass through the network. The output layer gives the prediction, and that's the output that will be sent on to the rest of the application. Another advantage of doing inference on the Android devices is that it allows leverage of all of the CPUs in the fleet of Shopping Cart 2.0s, as opposed to having to use a bank of GPUs back in the data warehouse. 



					</p>
					<p>To summarize the process:

						<ol>
							<li>Periodically take a picture of the contents of the basket.</li>
							<li>Use the picture as input to the local model and get the output of the inference as the object detections.</li>
							<li>Pass each detected object (name of items, bounding box coordinates) to the Kafka system via the <a href="https://docs.confluent.io/current/clients/producer.html">Producer API</a> for real-time processing.</li>

						</ol>


					</p>

				<div style="float: left; margin: 12px; border: 0px solid #999999;">
					<iframe src="http://www.oreilly.com/authors/widgets/782.html" height="380px" width="200px" scrolling="no" frameborder="0"></iframe>							
				</div>	

					
					<p>
						Given that their mandate is to use off-the-shelf components as much as possible to rapidly prototype, they're going to work with a pre-trained model from the <a href="https://www.tensorflow.org/">TensorFlow</a> <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">model zoo</a>. TensorFlow has a lot of community traction and support, so the team wants to try and leverage one of the object detection models offered from their website. The team has found some ARM9 boards (that will run <a href="https://www.tensorflow.org/mobile/android_build">TensorFlow on Android</a> with WIFI connectivity) with cameras for under $150, so creating 100 Shopping Cart 2.0 prototypes loaded up with an object deteciton model should cost around $15k for hardware. Another advantage is that TensorFlow has JVM bindings that run on Android as well, which can be integrated with the JVM code from Kafka.

					</p>




					<p>
						The team scans the TensorFlow model zoo and <a href="https://makarandtapaswi.wordpress.com/2012/07/02/intuition-behind-average-precision-and-map/">reads up on mAP scores</a> as an overall indication of model quality. (Resources on <a href="https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3">Understanding object detection and mAP scores</a>, and <a href="https://arxiv.org/abs/1611.10012">understanding speed/accuracy trade-offs in object detection</a>.) Inference speed is generally a concern, but given that this was a prototype and the team was more interested in better mAP scores, it was less of a concern here. The application did not need to produce a lot of inferences, so a few seconds of latency between taking the picture and sending object detections back to the Kafka cluster was not a big deal.


					</p>

					<p>

						The team chooses the <a href="http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz">COCO-pretrained Faster R-CNN with Resnet-101 model</a> because of its general mAP accuracy and decent file size. They gave a lot of consideration to the YOLOv2 model variant, but ended up going for another model that was slower but gave a better mAP score for the application (which makes a lot of difference when we're using a stock model for prototyping). The data scientists are relieved to know that there are resources for easily <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md">training a future custom model</a> on specific basket images (Example: <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md">training a pet detector based on Faster R-CNN Resnet 101</a>) once they get the prototype system running for management.

					</p>
					<p>
						With the base system design in place, the team can move on to getting JVM code working. The code needs to take a custom image as input and produce a raw inference output that can be passed to the <a href="https://docs.confluent.io/current/clients/producer.html">Kafka Producer API</a>, as we see in the next section.

					</p>




					</div>
				</div>
				<!-- end of section -->


				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Object Detection Model Inference at the Edge with TensorFlow</h2>

						<p>
							In this section, we'll focus on getting TensorFlow setup with Java code, the model loaded, and inferences produced from the model to send to the Kafka cluster.


							The core java classes for this object detection system running on each cart are listed below:
							<ul>
								<li><a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java">TFVision_ObjectDetection.java</a>: code to run the model inference with TensorFlow</li>
								<li><a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java">TFModelUtils.java</a>: support utilities for TensorFlow</li>
								<li><a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/VisualObject.java">VisualObject.java</a>: class to represent detected objects from model inference output</li>
								<li><a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java">ObjectDetectionProducer.java</a>: code tying the TensorFlow code into the <a href="https://docs.confluent.io/current/clients/producer.html">Kafka producer API</a></li>

							</ul>
						To get this project going we'll use Apache Maven so we'll need a pom.xml to bring in the needed dependencies. Here, we see the <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/pom.xml">pom.xml</a>:
						</p>


							<script src="http://gist-it.appspot.com/https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/pom.xml?slice=76:111"></script>

							<p>

							We can see the Confluent dependencies that will support the <a href="https://docs.confluent.io/current/clients/producer.html">Kafka Producer API</a> operations along with the TensorFlow dependencies needed to load a pre-trained model (component versions are in the variables section of the pom.xml file; specifically we're using TensorFlow 1.8 in this example). 

						</p>
						<p>
							Let's take a closer look at how we'll load the TensorFlow model and make inferences in Java with the TensorFlow R-CNN object detection model. In the code section below, we can see the <code><a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L96">scanAllFilesInDirectory(...)</a></code> method highlighted which performs the bulk of the work in the class.


						</p>



							<script src="http://gist-it.appspot.com/https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java?slice=95:140"></script>

						

						<p>
							The <code><a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L96">scanImageForObjects(...)</a></code> method takes 3 parameters:

							<ol>
								<li><b>modelFile</b>: the TensorFlow object detection model to load for inference</li>
								<li><b>labelMapFile</b>: list of labels the associated <b>modelFile</b> can output (i.e. "the vocabulary of labels the saved model understands")</li>
								<li><b>inputImageFile</b>: the image file path that we want to use as input to the <b>modelFile</b> to get object detections as output from</li>

							</ol>

							This class is a convenient wrapper around the base TensorFlow classes needed to load a <code><a href="https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/SavedModelBundle">SavedModelBundle</a></code> and produce inference output on an arbitrary TensorFlow model.							
							We'll point out a few key areas in the TensorFlow code above:<br/><br/>

							<ul>
								
								
								<li>Working with <code><a href="https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/SavedModelBundle">SavedModelBundle</a></code>, frozen graphs, and .pb files</li>
								<li><a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java">TFModelUtils.java</a></li>

								
								<li>Converting TensorFlow output into <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/VisualObject.java">VisualObject</a> class instances</li>

							</ul>

							The <code>SavedModelBundle</code> is handy because it contains all of the needed files to run a TensorFlow object detection model.

							The <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java">TFModelUtils.java</a> class is of note because it wraps functionality for doing things like <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java#L69">loading label files</a> and <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFModelUtils.java#L95">converting the image file input</a> into the proper vectorized <Code>Tensor&lt;UInt8&gt;</code> format. 

							After we get the output of the scores, classes, and bounding boxes from the TensorFlow inference output, the code <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L160">converts these into a VisualObject</a> class wrapper to make them easier to work with.
							Now that we've located the <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/VisualObject.java">VisualObjects</a> in our basket and given them classifications, let's move on to how we'll send the classified objects to the Kafka cluster for processing.

						</p>

					</div>
				</div>
				<!-- end of section -->



				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Integrating Shopping Cart 2.0 Detected Objects into an Apache Kafka Producer</h2>
						<p>
							To write data to a Kafka topic we need to use the Kafka Producer API. Apache Kafka is a JVM-based system so that makes it a relatively simple process to tie the object detection code into the code using the Producer API. In this example, we can see this happening in the <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java">ObjectDetectionProducer.java</a> class.

							We can see the code for this class highlighted below.

							

						</p>
						

							<script src="http://gist-it.appspot.com/https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java?slice=163:304"></script>							

						
						<p>
							We'll highlight a few key areas of the code:

							<ol>
								<li>Specifying a <A href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L239">Kafka topic</a> to send messages to</li>
								<li>Configuring the producer to <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L184">use the Avro GenericRecord API</a></li>
								<li>Laying out an <A href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L104">Avro schema</a> for the GenericRecord API to use</li>
								<li>Configuring the producer <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L176">properties</a></li>
								<li>Scanning all <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L245">image files in a directory</a></li>
								<li>Watching a <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L307">directory for incoming files</a></li>
								<li>Main <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java#L164">run loop</a> of the producer</li>
								
							</ol>

							The producer class can either scan a pre-existing directory and index all of the objects in the images of the directory or watch a directory for images as they arrive. The producer class uses the <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java">TFVision_ObjectDetection.java</a> we outlined in the previous section to analyze the images in the directory. The TFVision_ObjectDetection.java class's <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/vision/TFVision_ObjectDetection.java#L96"><code>scanImageForObjects(...)</code></a> method produces object detections which are then sent to the configured Kafka topic <code>shopping_cart_objects</code>. If we update our general architecture diagram from above it now looks like:


						</p>

						<div style="float: left; margin: 12px; border: 0px solid #999999;">

							<img src="./images/bcd_arch_part_2.png" style="width: 587px; height: 418px;" />

						</div>

						<p>
							We've configured this example to use the GenericRecord Avro API and the code contains an embedded Avro schema so that we can leverage the GenericRecord API as we're prototyping this application at this stage (for more details on how to use the Generic and SpecificRecord Avro API, check out our <A href="http://www.pattersonconsultingtn.com/blog/avro_101_w_kafka.html">blog post on Using Apache Avro with Apache Kafka</a>). We also include the address of the <a href="https://www.confluent.io/blog/schema-registry-kafka-stream-processing-yes-virginia-you-really-need-one/">Confluent Schema Registry</a> so the schema can be archived in its central Avro schema repository. 

						</p>



						<p>
							For demo purposes, this producer will come alive and then scan the image files in the directory we specify on the command line when we run the <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/CartCamApp/src/main/java/com/pattersonconsultingtn/kafka/examples/tf_object_detection/ObjectDetectionProducer.java">ObjectDetectionProducer.java</a> class. We include a set of pictures of items in shopping baskets for this demo, and we'll point the <code>ObjectDetectionProducer</code> class at the directory that contains this photos to run this demo. Additionally, we have provided a <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial/blob/master/TestKafkaProducer/src/main/java/com/pattersonconsultingtn/kafka/examples/test_producer/TestDetectionProducer.java">TestDetectionProducer.java</a> class that randomly generates items every 15 seconds. This allows testing where items are continuously produced, rather than needing to have a photo for each item.

					</div>
					<h2>Let's Try Out The Cart Cam Application Locally</h2>

					<div>

						<p>
						We have a <a href="https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial">Big Cloud Dealz github repository</a> setup for trying out the code. The main dependencies you will need to run this code is the project repository from github and the model from the TensorFlow ObjectDetection Model Zoo (download the Faster RCNN ResNet 101 model file locally <A href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz">from this link on the TensorFlow github repository</a>).


						<p>
							In the command list below, we can see:

						<ol>
							<li>We need to change into the CartCamApp subdirectory inside the main repository local directory</li>
							<li>We need to build the project with <code>mvn package</code></li>
							<li>We finally need to run the application itself with the <code>mvn exec:java ...</code> command</li>
						</ol>

						The Faster RCNN ResNet 101 model file should be saved somewhere locally such as <code>/Users/josh/Downloads/</code> and uncompressed, so the <code>saved_model/</code> subdirectory is available for our code to read.

					</p>
					<p>

						We don't need to worry about getting images to process as those are included in the repository at <code>./src/main/resources/cart_images</code> already as part of the project.

					</p>




					
<code><pre>git clone https://github.com/pattersonconsulting/BigCloudDealz_GreenLightSpecial.git
cd BigCloudDealz_GreenLightSpecial
cd CartCamApp

mvn package

mvn exec:java -Dexec.mainClass="com.pattersonconsultingtn.kafka.examples.tf_object_detection.ObjectDetectionProducer" \
  -Dexec.args="/Users/josh/Downloads/faster_rcnn_resnet101_coco_2018_01_28/saved_model/"					
</pre></code>

<p>
	After lots of startup console output from TensorFlow, you'll see the code taking each image and scanning it from objects as shown in the console output below:

</p>


<consoleoutput>...
* /Users/josh/Documents/workspace/PattersonConsulting/BigCloudDealz_GreenLightSpecial/CartCamApp/./src/main/resources/cart_images/basket_test_12.jpg
	Found cup                  (score: 0.9735)
Box: 0.030348212, 0.12714608, 0.3921343, 0.56470686
	Found dining table         (score: 0.9123)
Box: 0.0, 0.0, 1.0, 1.0
	Found bowl                 (score: 0.5170)
Box: 0.37673372, 0.2191577, 0.8414614, 0.7825875
Debug - Sending: cup
Debug - Sending: dining table
Debug - Sending: bowl
...</consoleoutput>

</div>

<p>
	Given we're just running the TensorFlow object detection code and we haven't setup Kafka yet, the code won't actually send the detected objects to Kafka. We'll see this part of the code in action in parts 3 and 4 where we turn on Kafka and then have the CartCampApp actually write to a topic via the Kafka producer API.

	</p>

				</div>
				<!-- end of section -->

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">AT THE END OF EVERYDAY, BEFORE I HIT THE SACK, I LOOK AT MYSELF IN THE MIRROR AND ASK MYSELF: &quot;DID WE BRING THE WOOOOOO TODAY?&quot; <br><br>ALSO: I ENJOY STARING GREATNESS IN THE FACE.</p>&mdash; BigCloudRon (@BigCloudRon1) <a href="https://twitter.com/BigCloudRon1/status/1027367688543379457?ref_src=twsrc%5Etfw">August 9, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>				


				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h2>Summary</h2>

						<p>
							In part 2 of this series on re-inventing the shopping cart we walked the reader through:

							<ol>
								<li>Selecting an object detection model</li>
								<li>Integrating the model to serve predictions</li>
								<li>Wiring the predictings into Kafka with the Producer API</li>


							</ol>

							In part 3 of the series, we'll set up Kafka and pull in inventory information from MySQL to enrich the data coming from the shopping carts.


						</p>
						
						


					</div>
				</div>
				<!-- end of section -->


						<div style="border: 1px solid #999999; background-color: #EEEEEE; padding: 16px; margin: 32px;">

						<h3>More Notes on Model Integration and Model Lifecycle Management</h3>
						  <p>
						  <i>
						  	Obviously for this example we're hard-wiring a model into the Shopping Cart 2.0 project in a way that's great for proof of concepts, yet doesn't address many of the production lifecycle issues that arise.
						  	Some of these considerations include:

							<ul>
								
								<li>Why not send images to Kafka or the data lake?</li>
								<li>How often do we retrain this model?</li>								
								<li>How would we swap out or roll-back the model in production?</li>
								
							</ul>
							One great reason to not send images back to the data lake is that we might capture customer-sensitive images which could cause legal issues in certain scenarios. Another reason for not capturing the images is from a pure resource standpoint. It would require more storage and processing resources be used to move the images around.


							</i></p>
							<p><i>
								The R-CNN model the team uses in this example is good to prove to management that this concept "works," yet has a limited initial vocabulary of objects it can recognize. A real production version of this model would need to fine tune against the full inventory of the retail chain and would require retraining every time the store carried a new item. A re-train event would need to be done in a batch setting back on the data lake (probably leveraging GPUs).

							</i></p>

							<p><i>
								Once we have a new re-trained model, we'll need to be able to deploy the model to system. We have two options: we either deploy it each night after the store closes, or we do it while people are shopping and using the system. We feel the best approach in terms of model management long term, is to leverage a <A href="https://www.oreilly.com/ideas/integrating-convolutional-neural-networks-into-enterprise-applications">model server system</a> so the support / Ops team can treat each model as it would a RDBMS table. There are several variants of model servers today. Here are a few notable ones:

								<ul>
									<li><b>Kubeflow's <A href="https://www.kubeflow.org/docs/components/serving/kfserving/">KFServing</a> for serving models (supports: TensorFlow, Pytorch, XGBoost, ONNX, Scikit-Learn, TensorRT), vectorization transformers, traffic routing, more</b></li>
									<li>Official <a href="https://github.com/tensorflow/serving">TensorFlow Serving Project</a> and then Google's cloud model hosting offerings</li>
									<li>Hosting <a href="https://docs.microsoft.com/en-us/visualstudio/ai/tensorflow-vm">TensorFlow models on an Azure VM</a> and deploying <a href="https://docs.microsoft.com/en-us/azure/machine-learning/desktop-workbench/model-management-service-deploy">model as web service</a> on Azure</li>

									<li>Amazon <A href="https://aws.amazon.com/blogs/machine-learning/introducing-model-server-for-apache-mxnet/">MXNet Model Server</a></li>
									

									<li>Skymind's <a href="https://docs.skymind.ai/docs">SKIL Model Server</a> for TensorFlow model hosting</li>

								</ul>

								For the purposes of brevity and practicality in this example, we will not integrate a model server and will leave that as an exercise for the reader to explore later. For a further discussion on architecture ideas around machine learning infrastructure, please <a href="http://www.pattersonconsultingtn.com/contact.html">reach out to the Patterson Consulting team</a>. We'd love to talk with your team about topics such as:


								<ul>
									<li>Data Science: <a href="http://www.pattersonconsultingtn.com/offerings/data_science_offerings.html">from overview to implementation</a></li>
									<li><a href="http://www.pattersonconsultingtn.com/offerings/managed_kubeflow.html">Managed Kubeflow</a> for hosting models (on-premise or in the cloud)</li>
									<li>Custom model design</li>
									<li><a href="http://www.pattersonconsultingtn.com/offerings/data_science_offerings.html">Managed models</a> as a service</li>
									<li>Hardware design for your data center</li>

								</ul>

							</i></p>


							</div>	
<!--
						<h4><a href="http://www.pattersonconsultingtn.com/blog/greenlightspecial_part3.html">Part 3</a></h4>
-->
					</div>
				</div>
				




			</div>
		</div>






		<!-- Slider -->
		<!--
		<footer id="fh5co-footer" role="contentinfo">
			<div class="container">
				<div class="row row-bottom-padded-sm">
					<div class="col-md-4 col-sm-12">
					</div>
					<div class="col-md-3 col-md-push-1 col-sm-12 col-sm-push-0">
						<div class="fh5co-footer-widget">
						</div>
					</div>
					<div class="col-md-3 col-md-push-2 col-sm-12 col-sm-push-0">
						
						<div class="fh5co-footer-widget">
							<h3>Follow us</h3>
							<ul class="fh5co-social">
								<li class="twitter"><a href="https://twitter.com/PattersonCnsltg"><i class="icon-twitter"></i></a></li>
								<li class="linkedin"><a href="https://www.linkedin.com/in/joshlpatterson/"><i class="icon-linkedin"></i></a></li>
								<li class="message"><a href="mailto:josh@pattersonconsultingtn.com"><i class="icon-mail"></i></a></li>
							</ul>
						</div>
					</div>

				</div>

			</div>
		</footer>
	-->
	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>
