
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-119541534-1');
</script>
		
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Patterson Consulting: Blog - Effects of Batch Size, Acknowledgments, and Compression on Kafka Throughput</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="blog page for Patterson Consulting" />
	<meta name="keywords" content="blog, patterson consulting, deep learning, machine learning, apache hadoop, apache spark, etl, consulting" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}
	</style>

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
					<ul>
						<li><a href="../about.html">About</a></li>
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Services</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../big_data_apps.html">Hadoop Applications</a></li>
										<li><a href="../vision_apps.html">Computer Vision Applications</a></li>
										<li><a href="../sensor_apps.html">Sensor Applications</a></li>
										<li><a href="../exec_strategy.html">Executive Strategy</a></li>

									</ul>
								</div>
							</div>
						</li>
						<!--
						<li><a href="portfolio.html">Portfolio</a></li>
-->
						<li class="has-sub">
							<div class="drop-down-menu">
								<a href="#">Technologies</a>
								<div class="dropdown-menu-wrap">
									<ul>
										<li><a href="../deep_learning.html">Deep Learning</a></li>
										<li><a href="../hadoop.html">Apache Hadoop</a></li>										
									</ul>
								</div>
							</div>
						</li>
					
						<li class="cta"><a href="../contact.html">Contact</a></li>
					</ul>
				</nav>
			</div>
		</header>
		<!-- Header -->

<!--
		<div class="fh5co-slider" >
			<div class="container" >
				
				<div class="cd-hero__content cd-hero__content--half-width" style="width: 80%; padding-left: 50px;">
						<h1>Rail, Aquariums, and Data</h1>
				</div>		
			</div>
		</div>
-->

		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h1>Effects of Batch Size, Acknowledgments, and Compression on Kafka Throughput</h1>
						<p>Author: Stuart Eudaly</p>
						<p>Date: December 20th, 2018</p>
						
						<p>
							<i>In this blog article, we aim to give the reader a sense of how batch size, acknowledgments, and compression affect the throughput of a Kafka cluster. Specifically, we will be looking at how these settings have an impact on producer-to-broker throughput.</i>

						</p>


						<p>

							<img src="./images/kafka_logo.png" style="width: 250px; height: 85px; float: right; margin: 12px; border: 0px solid #999999;" />


While certainly not the only metric to be concerned about, maximizing throughput is often a main concern when tuning a system. Depending on your specific use case, throughput may even be the most valuable goal to strive for (as opposed to latency, availability, durability, etc.). Even on modest hardware, Kafka allows for some incredible throughput if set up correctly. LinkedIn (where Kafka originated) <a href="https://engineering.linkedin.com/blog/2017/08/open-sourcing-kafka-cruise-control">has a Kafka deployment</a> that handles over 2 trillion messages per day!
</p>
<p>
When it comes to a Kafka setup, throughput from producers to brokers is determined by multiple factors. We are going to look at three of those factors in this post: batch size, acknowledgments, and compression. If you’d like more information, a good resource for learning about the basics of Kafka optimization can be found in this <a href="https://www.confluent.io/white-paper/optimizing-your-apache-kafka-deployment/">white paper on Confluent's web site</a>.
</p>
<p>
The goal here is not to say “this is the only right way to configure your Kafka setup,” but rather to give a general awareness of how making changes in these areas can affect the overall throughput of the system. It should also be noted that every system is different and results will not be exactly the same as what you see here. However, the trends seen here should apply in most (if not all) scenarios.


						</p>


					</div>
				</div>
				<!-- end of section -->

				<!-- start of section -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h3>Setting Things Up</h3>
						<p>
For this post, I have set up Kafka using a Confluent distribution. For instructions on how to get started with Confluent’s distribution of Kafka, I recommend starting with this <a href="https://docs.confluent.io/current/quickstart/cos-quickstart.html#cos-quickstart">Confluent quick start article</a>. In order to test producer throughput, we will be using the <kbd>kafka-producer-perf-test</kbd> found in <code>[confluent directory]/bin/kafka-producer-perf-test</code>. For help with the usage of the test, run: <kbd>./kafka-producer-perf-test -h</kbd>.
</p>
<p>
I set up this Kafka cluster using <a href="http://www.amazon.com/aws/">AWS</a>. In order to ensure that I had sufficient hardware for Kafka to run efficiently, I followed the recommendations found in this <a href="https://www.confluent.io/resources/apache-kafka-confluent-enterprise-reference-architecture/">white paper by Confluent about reference architecture</a>. For these tests, Kafka was set up on three “r5.xlarge” instances. These instances each feature 4 vCPUs, 32GiB of RAM, and 10Gbps networking. 

To see the full specs, take a look at the <a href="https://aws.amazon.com/ec2/instance-types/">AWS reference article on instance types</a>. The producer for this test was an “r5.large” instance, which is similar to the xlarge instances, but has 2 vCPUs and 16GiB of RAM. For more information on setting up Kafka on AWS, check out <a href="http://www.pattersonconsultingtn.com/blog/set_up_kafka_on_aws.html">this blog post</a>.


						</p>

						<p>
							<h3>Batch Size</h3>

When a producer wants to send a message to a partition on a broker, that message can be sent immediately or can be batched and sent together with other messages. Because of the network and CPU overhead involved with sending messages between producers and brokers, throughput can be increased by sending messages together. As is probably obvious, this batching of messages to increase throughput is done at the expense of latency. If a message is produced at the beginning of a batch, it has to wait to be sent until the batch fills up (or a specified amount of time has passed), meaning it arrives at the broker later than it could have if sent immediately.
						</p>

						<p>

<!--
<pre><code></code></pre>
<kbd>curl</kbd>
-->
All properties for producers can be found and changed in their respective producer.properties files. (For an in-depth look at all of the producer configuration settings, take a look at <a href="https://kafka.apache.org/documentation/#producerconfigs">Kafka’s documentation</a>.) This file can be found in <code>[confluent directory]/etc/kafka/</code> and contains the <code>batch.size</code> parameter, which  is measured in bytes:

<pre><code># the default batch size in bytes when batching multiple records sent to a partition
#batch.size=
</code></pre>

There is also a “linger” setting which determines how long a batch will wait before being sent if it does not fill the batch size. By default, this is set to 0, which means that a producer will send messages as soon as they become available. That means that NO batching is happening at all. In order to test how batch size impacts throughput, we’re going to set the linger parameter to a very high amount, like 100,000ms. This will ensure that a batch is filled and sent before the maximum linger time is met.
						</p>

						<p>

The batch size should be set in the <code>producer.properties</code> file once a value has been determined. However, when running the perf test, <code>--producer-props</code> overrides the properties file. So, for our tests, we’ll be using the command-line argument instead. Another factor here is the buffer size. The <code>buffer.memory</code> is the amount of memory in bytes that the producer is allowed to utilize to store a batch before sending. This means that the buffer needs to be AT LEAST as big as the batch size. The default value for buffer.memory is over 30MB at 33,554,432 bytes. In these tests, I was not going to send a batch larger than about 500MB, so I set the buffer to roughly 4GB. Here is what the Apache’s documentation linked earlier has to say about <code>buffer.memory</code>:
						</p>

						<p><i>

“This setting should correspond roughly to the total memory the producer will use, but is not a hard bound since not all memory the producer uses is used for buffering. Some additional memory will be used for compression (if compression is enabled) as well as for maintaining in-flight requests.”
						</i></p>

						<p>

I also discovered that increasing the buffer size DOES NOT increase the Java heap size for Kafka. In order to do this, you can set the environment variable in a terminal before starting Kafka with:
<consoleoutput>export KAFKA_HEAP_OPTS="-Xmx8G -Xms8G”
</consoleoutput>
The “8G” portion of that command is what sets the heap size. I settled on 8GB as all the machines I was dealing with had at least 8GB, and the buffer memory was set at 4GB. For more information, check out this <a href="https://stackoverflow.com/questions/27681511/how-do-i-set-the-java-options-for-kafka">Stack Overflow question on the topic</a>.
						</p>

						<p>

Now, enough about setup. Let’s take a look at some results!





						</p>

						<p>
							<h3>Results for Batch Size Tests</h3>

Each test for an individual batch size was done three times then averaged. The actual command given was as follows (using 1,000 batch size as an example):

<consoleoutput>./kafka-producer-perf-test --topic testTopic --num-records 1000000 --throughput -1 --producer-props bootstrap.servers=[serverIP]:9092 batch.size=1000 linger.ms=100000 buffer.memory=4294967296 request.timeout.ms=300000 --record-size 1000
</consoleoutput>
						</p>

						<p>

Here’s what each of those arguments mean:
<br>
							<pre>
--topic testTopic		The topic the perf test will write to
--num-records 1000000		The total number of records to send for the test
--throughput -1			The maximum throughput for the test
--producer-props		The producer properties
	bootstrap.servers	The location of one of the Kafka brokers
	batch.size		The batch size in bytes
	linger.ms		The amount of time the producer will wait if a batch does not fill
	buffer.memory		The amount of RAM allocated for the producer to store batches
	request.timeout.ms	The amount of time before a timeout from a request occurs
--record-size			The size of each record in bytes
</pre>
						</p>

						<p>

A few notes:
<ul>
<li>I chose to send 1,000,000 records to allow for a good throughput measurement.</li>
<li>Setting throughput to “-1” means there is no maximum throughput.</li>
<li>Everything following <code>--producer-props</code> overrides what is in the producer.properties file.</li>
<li>For my testing, I needed to increase the <code>request.timeout.ms</code> value for some of the smaller batch sizes, as messages were being produced much faster than they were able to be received by the brokers.</li>
</ul>

In the chart below, we can see the results of these set of test runs.

						</p>

						<p>
							<img src="./images/throughput_results_1_chart.png" style="width: 605px; height: 302px; margin: 12px; border: 0px solid #999999;" />


							<img src="./images/throughput_results_1_table.png" style="width: 314px; height: 226px;  margin: 12px; border: 0px solid #999999;" />
						</p>
						

						<p>



As can be seen above, the larger the batch size, the higher the throughput. It should also be noted that message size plays into throughput. However, message sizes can vary between producers and batch size can be considered rather than message size. In other words, as long as the message size is less than or equal to the batch size, setting an appropriate batch size will determine how many bytes are sent per request between producers and brokers.



					</p>
					<p>
						<h3>Results for Acknowledgments Tests</h3>

When a producer sends a request to the brokers, an acknowledgment is sent back to the producer to confirm receipt of the request. Kafka producers have three settings for acknowledgments:
						</p>

						<p>

<ol>
<li>A setting of “1” (the default) which means that producers only require one acknowledgment from the broker leader. If the leader fails immediately after receiving a record from the producer, but before the followers can copy it, that record will be lost.</li>
<li>A setting of “all” or “-1” which means that producers require acknowledgments from every broker that contains the topic. This ensures durability of the record as long as at least one in sync replica remains online.</li>
<li>A setting of “0” which means that producers do not require any acknowledgments from brokers. This setting does not guarantee durability of records.</li>
</ol>

						</p>


						<p>
							<img src="./images/throughput_results_2_chart.png" style="width: 600px; height: 314px; margin: 12px; border: 0px solid #999999;" />


							<img src="./images/throughput_results_2_table.png" style="width: 314px; height: 130px;  margin: 12px; border: 0px solid #999999;" />
						</p>						

						<p>

As might already be obvious, requiring more acknowledgments means the producer has to wait before sending more records. As can be seen in the results below, the less acknowledgments required by the producer, the higher the throughput. This comes, however, at the expense of durability. The only change in the terminal command is to add <code>acks=0</code> or <code>acks=-1</code> to the <code>--producer-props</code> argument. For these tests, I chose a set batch size (10,000 bytes) and simply changed the “acks” property. Because the default is “1,” I used the original results for a batch of 10,000 bytes that was tested earlier.


					</p>

					<p>
							<h3>Results for Compression Tests</h3>



Compressing messages in Kafka works on entire batches. According to Kafka’s documentation on <a href="https://kafka.apache.org/documentation/#producerconfigs">producer configurations</a>: <br><br> <p><i>“Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).”</i></p> In order to show the differences in throughput of the different compression methods, I have chosen a single batch size of 10,000 bytes. 
</p>
<p>
Kafka supports three types of compression: 
<ol>
	<li>gzip</li>
	<li>snappy</li>
	<li>lz4</li>
</ol>

In order to change these, simply use the <code>--producer-props</code> argument <code>compression.type</code>. Again, the original results for 10,000 bytes found in the batch testing earlier was used for the “no compression” test.
						</p>

						<p>
							<img src="./images/throughput_results_3_chart.png" style="width: 607px; height: 316px; margin: 12px; border: 0px solid #999999;" />


							<img src="./images/throughput_results_3_table.png" style="width: 314px; height: 162px;  margin: 12px; border: 0px solid #999999;" />
						</p>						


						<p>

Note that compression does introduce CPU overhead. As stated in the <a href="http://kafka.apache.org/documentation.html#design_compression">documentation on compression</a>: <p><i>“Kafka supports this with an efficient batching format. A batch of messages can be clumped together compressed and sent to the server in this form. This batch of messages will be written in compressed form and will remain compressed in the log and will only be decompressed by the consumer.”</i></p> This means that the producer and consumer (though not the broker!) have to compress/decompress messages in addition to any work involved in simply producing/consuming them. However, in your specific scenario, CPU may not be the bottleneck. If that is the case, compressing messages can greatly increase throughput. Similar to “acks” above, the only change in the terminal command is to add <code>compression.type=gzip</code> (or any of the other types) to the <code>--producer-props</code> argument.



					</p>
					<p>
							

The results show that any compression increases throughput. For this particular set of tests, throughput is increased by more than double for all three compression types with the “lz4” having the highest increase in throughput with over five times that of no compression.
						</p>

						<p>
							<h3>Conclusion</h3>

In this post, we looked at three different factors that can be altered to increase throughput: batch size, acknowledgements, and compression. While every setup and scenario is different, these settings can be changed to (hopefully) achieve the best throughput for your use case.



					</p>

<!--
							A quote from Confluent's site goes on to state:
						<blockquote class="w3-panel w3-leftbar w3-light-grey" style="padding: 16px; font-size: 12px;">
						  <p style="font-size: 14px;">
						  <i>"Consider a simple model of a retail store. The core streams in retail are sales of products, orders placed for new products, and shipments of products that arrive. The “inventory on hand” is a table computed off the sale and shipment streams which add and subtract from our stock of products on hand. Two key stream processing operations for a retail outlet are re-ordering products when the stock starts to run low, and adjusting prices as supply and demand change."</i></p>
						  <p>Jay Kreps' Blog Article: <a href="https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/">"Introducing Kafka Streams: Stream Processing Made Simple"</a></p>
						</blockquote>		
-->


					</div>
				</div>
				<!-- end of section -->





			</div>
		</div>




	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>
